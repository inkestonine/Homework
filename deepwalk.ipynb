{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_num(num, workers):\n",
    "    if num % workers == 0:\n",
    "        return [num//workers]*workers\n",
    "    else:\n",
    "        return [num//workers]*workers + [num % workers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alias_table(area_ratio):\n",
    "    \"\"\"\n",
    "    :param area_ratio: sum(area_ratio)=1\n",
    "    :return: accept,alias\n",
    "    \"\"\"\n",
    "    l = len(area_ratio)\n",
    "    accept, alias = [0] * l, [0] * l\n",
    "    small, large = [], []\n",
    "    area_ratio_ = np.array(area_ratio) * l\n",
    "    for i, prob in enumerate(area_ratio_):\n",
    "        if prob < 1.0:\n",
    "            small.append(i)\n",
    "        else:\n",
    "            large.append(i)\n",
    "\n",
    "    while small and large:\n",
    "        small_idx, large_idx = small.pop(), large.pop()\n",
    "        accept[small_idx] = area_ratio_[small_idx]\n",
    "        alias[small_idx] = large_idx\n",
    "        area_ratio_[large_idx] = area_ratio_[large_idx] - \\\n",
    "            (1 - area_ratio_[small_idx])\n",
    "        if area_ratio_[large_idx] < 1.0:\n",
    "            small.append(large_idx)\n",
    "        else:\n",
    "            large.append(large_idx)\n",
    "\n",
    "    while large:\n",
    "        large_idx = large.pop()\n",
    "        accept[large_idx] = 1\n",
    "    while small:\n",
    "        small_idx = small.pop()\n",
    "        accept[small_idx] = 1\n",
    "\n",
    "    return accept, alias\n",
    "\n",
    "\n",
    "def alias_sample(accept, alias):\n",
    "    \"\"\"\n",
    "    :param accept:\n",
    "    :param alias:\n",
    "    :return: sample index\n",
    "    \"\"\"\n",
    "    N = len(accept)\n",
    "    i = int(np.random.random()*N)\n",
    "    r = np.random.random()\n",
    "    if r < accept[i]:\n",
    "        return i\n",
    "    else:\n",
    "        return alias[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWalker:\n",
    "    def __init__(self, G, p=1, q=1, use_rejection_sampling=0):\n",
    "        \"\"\"\n",
    "        :param G:\n",
    "        :param p: Return parameter,controls the likelihood of immediately revisiting a node in the walk.\n",
    "        :param q: In-out parameter,allows the search to differentiate between “inward” and “outward” nodes\n",
    "        :param use_rejection_sampling: Whether to use the rejection sampling strategy in node2vec.\n",
    "        \"\"\"\n",
    "        self.G = G\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.use_rejection_sampling = use_rejection_sampling\n",
    "\n",
    "    def deepwalk_walk(self, walk_length, start_node):\n",
    "\n",
    "        walk = [start_node]\n",
    "\n",
    "        while len(walk) < walk_length:\n",
    "            cur = walk[-1]\n",
    "            cur_nbrs = list(self.G.neighbors(cur))\n",
    "            if len(cur_nbrs) > 0:\n",
    "                walk.append(random.choice(cur_nbrs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    def node2vec_walk(self, walk_length, start_node):\n",
    "\n",
    "        G = self.G\n",
    "        alias_nodes = self.alias_nodes\n",
    "        alias_edges = self.alias_edges\n",
    "\n",
    "        walk = [start_node]\n",
    "\n",
    "        while len(walk) < walk_length:\n",
    "            cur = walk[-1]\n",
    "            cur_nbrs = list(G.neighbors(cur))\n",
    "            if len(cur_nbrs) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(\n",
    "                        cur_nbrs[alias_sample(alias_nodes[cur][0], alias_nodes[cur][1])])\n",
    "                else:\n",
    "                    prev = walk[-2]\n",
    "                    edge = (prev, cur)\n",
    "                    next_node = cur_nbrs[alias_sample(alias_edges[edge][0],\n",
    "                                                      alias_edges[edge][1])]\n",
    "                    walk.append(next_node)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return walk\n",
    "\n",
    "    def node2vec_walk2(self, walk_length, start_node):\n",
    "        \"\"\"\n",
    "        Reference:\n",
    "        KnightKing: A Fast Distributed Graph Random Walk Engine\n",
    "        http://madsys.cs.tsinghua.edu.cn/publications/SOSP19-yang.pdf\n",
    "        \"\"\"\n",
    "\n",
    "        def rejection_sample(inv_p, inv_q, nbrs_num):\n",
    "            upper_bound = max(1.0, max(inv_p, inv_q))\n",
    "            lower_bound = min(1.0, min(inv_p, inv_q))\n",
    "            shatter = 0\n",
    "            second_upper_bound = max(1.0, inv_q)\n",
    "            if (inv_p > second_upper_bound):\n",
    "                shatter = second_upper_bound / nbrs_num\n",
    "                upper_bound = second_upper_bound + shatter\n",
    "            return upper_bound, lower_bound, shatter\n",
    "\n",
    "        G = self.G\n",
    "        alias_nodes = self.alias_nodes\n",
    "        inv_p = 1.0 / self.p\n",
    "        inv_q = 1.0 / self.q\n",
    "        walk = [start_node]\n",
    "        while len(walk) < walk_length:\n",
    "            cur = walk[-1]\n",
    "            cur_nbrs = list(G.neighbors(cur))\n",
    "            if len(cur_nbrs) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(\n",
    "                        cur_nbrs[alias_sample(alias_nodes[cur][0], alias_nodes[cur][1])])\n",
    "                else:\n",
    "                    upper_bound, lower_bound, shatter = rejection_sample(\n",
    "                        inv_p, inv_q, len(cur_nbrs))\n",
    "                    prev = walk[-2]\n",
    "                    prev_nbrs = set(G.neighbors(prev))\n",
    "                    while True:\n",
    "                        prob = random.random() * upper_bound\n",
    "                        if (prob + shatter >= upper_bound):\n",
    "                            next_node = prev\n",
    "                            break\n",
    "                        next_node = cur_nbrs[alias_sample(\n",
    "                            alias_nodes[cur][0], alias_nodes[cur][1])]\n",
    "                        if (prob < lower_bound):\n",
    "                            break\n",
    "                        if (prob < inv_p and next_node == prev):\n",
    "                            break\n",
    "                        _prob = 1.0 if next_node in prev_nbrs else inv_q\n",
    "                        if (prob < _prob):\n",
    "                            break\n",
    "                    walk.append(next_node)\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    def simulate_walks(self, num_walks, walk_length, workers=1, verbose=0):\n",
    "\n",
    "        G = self.G\n",
    "\n",
    "        nodes = list(G.nodes())\n",
    "\n",
    "        results = Parallel(n_jobs=workers, verbose=verbose, )(\n",
    "            delayed(self._simulate_walks)(nodes, num, walk_length) for num in\n",
    "            partition_num(num_walks, workers))\n",
    "\n",
    "        walks = list(itertools.chain(*results))\n",
    "\n",
    "        return walks\n",
    "\n",
    "    def _simulate_walks(self, nodes, num_walks, walk_length,):\n",
    "        walks = []\n",
    "        for _ in range(num_walks):\n",
    "            random.shuffle(nodes)\n",
    "            for v in nodes:\n",
    "                if self.p == 1 and self.q == 1:\n",
    "                    walks.append(self.deepwalk_walk(\n",
    "                        walk_length=walk_length, start_node=v))\n",
    "                elif self.use_rejection_sampling:\n",
    "                    walks.append(self.node2vec_walk2(\n",
    "                        walk_length=walk_length, start_node=v))\n",
    "                else:\n",
    "                    walks.append(self.node2vec_walk(\n",
    "                        walk_length=walk_length, start_node=v))\n",
    "        return walks\n",
    "\n",
    "    def get_alias_edge(self, t, v):\n",
    "        \"\"\"\n",
    "        compute unnormalized transition probability between nodes v and its neighbors give the previous visited node t.\n",
    "        :param t:\n",
    "        :param v:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        G = self.G\n",
    "        p = self.p\n",
    "        q = self.q\n",
    "\n",
    "        unnormalized_probs = []\n",
    "        for x in G.neighbors(v):\n",
    "            weight = G[v][x].get('weight', 1.0)  # w_vx\n",
    "            if x == t:  # d_tx == 0\n",
    "                unnormalized_probs.append(weight/p)\n",
    "            elif G.has_edge(x, t):  # d_tx == 1\n",
    "                unnormalized_probs.append(weight)\n",
    "            else:  # d_tx > 1\n",
    "                unnormalized_probs.append(weight/q)\n",
    "        norm_const = sum(unnormalized_probs)\n",
    "        normalized_probs = [\n",
    "            float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
    "\n",
    "        return create_alias_table(normalized_probs)\n",
    "\n",
    "    def preprocess_transition_probs(self):\n",
    "        \"\"\"\n",
    "        Preprocessing of transition probabilities for guiding the random walks.\n",
    "        \"\"\"\n",
    "        G = self.G\n",
    "        alias_nodes = {}\n",
    "        for node in G.nodes():\n",
    "            unnormalized_probs = [G[node][nbr].get('weight', 1.0)\n",
    "                                  for nbr in G.neighbors(node)]\n",
    "            norm_const = sum(unnormalized_probs)\n",
    "            normalized_probs = [\n",
    "                float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
    "            alias_nodes[node] = create_alias_table(normalized_probs)\n",
    "\n",
    "        if not self.use_rejection_sampling:\n",
    "            alias_edges = {}\n",
    "\n",
    "            for edge in G.edges():\n",
    "                alias_edges[edge] = self.get_alias_edge(edge[0], edge[1])\n",
    "                if not G.is_directed():\n",
    "                    alias_edges[(edge[1], edge[0])] = self.get_alias_edge(edge[1], edge[0])\n",
    "                self.alias_edges = alias_edges\n",
    "\n",
    "        self.alias_nodes = alias_nodes\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepWalk:\n",
    "    def __init__(self, graph, walk_length, num_walks, workers=1):\n",
    "\n",
    "        self.graph = graph\n",
    "        self.w2v_model = None\n",
    "        self._embeddings = {}\n",
    "\n",
    "        self.walker = RandomWalker(\n",
    "            graph, p=1, q=1, )\n",
    "        self.sentences = self.walker.simulate_walks(\n",
    "            num_walks=num_walks, walk_length=walk_length, workers=workers, verbose=1)\n",
    "\n",
    "    def train(self, embed_size=16, window_size=5, workers=3, iter=5, **kwargs): # try :embed_size=64 / 32 ..8\n",
    "\n",
    "        kwargs[\"sentences\"] = self.sentences\n",
    "        kwargs[\"min_count\"] = kwargs.get(\"min_count\", 0)\n",
    "        kwargs[\"size\"] = embed_size\n",
    "        kwargs[\"sg\"] = 1  # skip gram\n",
    "        kwargs[\"hs\"] = 1  # deepwalk use Hierarchical Softmax\n",
    "        kwargs[\"workers\"] = workers\n",
    "        kwargs[\"window\"] = window_size\n",
    "        kwargs[\"iter\"] = iter\n",
    "\n",
    "        print(\"Learning embedding vectors...\")\n",
    "        model = Word2Vec(**kwargs)\n",
    "        print(\"Learning embedding vectors done!\")\n",
    "\n",
    "        self.w2v_model = model\n",
    "        return model\n",
    "\n",
    "    def get_embeddings(self,):\n",
    "        if self.w2v_model is None:\n",
    "            print(\"model not train\")\n",
    "            return {}\n",
    "\n",
    "        self._embeddings = {}\n",
    "        for word in self.graph.nodes():\n",
    "            self._embeddings[word] = self.w2v_model.wv[word]\n",
    "\n",
    "        return self._embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbedding(G):\n",
    "    model = DeepWalk(G, walk_length=10, num_walks=80, workers=8) #init model\n",
    "    model.train(window_size=5,iter=3) # train model\n",
    "    embeddings = model.get_embeddings() # get embedding vectors\n",
    "    return embeddings"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
